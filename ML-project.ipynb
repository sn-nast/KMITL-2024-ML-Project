{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sunsu\\AppData\\Local\\Temp\\ipykernel_29264\\489979449.py:2: DtypeWarning: Columns (27) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"dataset/HomeC.csv\")  # Change filename if needed\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"dataset/HomeC.csv\")  # Change filename if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "time",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "use [kW]",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "gen [kW]",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "House overall [kW]",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Dishwasher [kW]",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Furnace 1 [kW]",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Furnace 2 [kW]",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Home office [kW]",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Fridge [kW]",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Wine cellar [kW]",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Garage door [kW]",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Kitchen 12 [kW]",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Kitchen 14 [kW]",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Kitchen 38 [kW]",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Barn [kW]",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Well [kW]",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Microwave [kW]",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Living room [kW]",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Solar [kW]",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "temperature",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "icon",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "humidity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "visibility",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "summary",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "apparentTemperature",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pressure",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "windSpeed",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "cloudCover",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "windBearing",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "precipIntensity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "dewPoint",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "precipProbability",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "1784ba8e-ce8f-43b3-9b7e-389d027d149b",
       "rows": [
        [
         "0",
         "1451624400",
         "0.932833333",
         "0.003483333",
         "0.932833333",
         "3.33e-05",
         "0.0207",
         "0.061916667",
         "0.442633333",
         "0.12415",
         "0.006983333",
         "0.013083333",
         "0.000416667",
         "0.00015",
         "0.0",
         "0.03135",
         "0.001016667",
         "0.004066667",
         "0.001516667",
         "0.003483333",
         "36.14",
         "clear-night",
         "0.62",
         "10.0",
         "Clear",
         "29.26",
         "1016.91",
         "9.18",
         "cloudCover",
         "282",
         "0.0",
         "24.4",
         "0.0"
        ],
        [
         "1",
         "1451624401",
         "0.934333333",
         "0.003466667",
         "0.934333333",
         "0.0",
         "0.020716667",
         "0.063816667",
         "0.444066667",
         "0.124",
         "0.006983333",
         "0.013116667",
         "0.000416667",
         "0.00015",
         "0.0",
         "0.0315",
         "0.001016667",
         "0.004066667",
         "0.00165",
         "0.003466667",
         "36.14",
         "clear-night",
         "0.62",
         "10.0",
         "Clear",
         "29.26",
         "1016.91",
         "9.18",
         "cloudCover",
         "282",
         "0.0",
         "24.4",
         "0.0"
        ],
        [
         "2",
         "1451624402",
         "0.931816667",
         "0.003466667",
         "0.931816667",
         "1.67e-05",
         "0.0207",
         "0.062316667",
         "0.446066667",
         "0.123533333",
         "0.006983333",
         "0.013083333",
         "0.000433333",
         "0.000166667",
         "1.67e-05",
         "0.031516667",
         "0.001",
         "0.004066667",
         "0.00165",
         "0.003466667",
         "36.14",
         "clear-night",
         "0.62",
         "10.0",
         "Clear",
         "29.26",
         "1016.91",
         "9.18",
         "cloudCover",
         "282",
         "0.0",
         "24.4",
         "0.0"
        ],
        [
         "3",
         "1451624403",
         "1.02205",
         "0.003483333",
         "1.02205",
         "1.67e-05",
         "0.1069",
         "0.068516667",
         "0.446583333",
         "0.123133333",
         "0.006983333",
         "0.013",
         "0.000433333",
         "0.000216667",
         "0.0",
         "0.0315",
         "0.001016667",
         "0.004066667",
         "0.001616667",
         "0.003483333",
         "36.14",
         "clear-night",
         "0.62",
         "10.0",
         "Clear",
         "29.26",
         "1016.91",
         "9.18",
         "cloudCover",
         "282",
         "0.0",
         "24.4",
         "0.0"
        ],
        [
         "4",
         "1451624404",
         "1.1394",
         "0.003466667",
         "1.1394",
         "0.000133333",
         "0.236933333",
         "0.063983333",
         "0.446533333",
         "0.12285",
         "0.00685",
         "0.012783333",
         "0.00045",
         "0.000333333",
         "0.0",
         "0.0315",
         "0.001016667",
         "0.004066667",
         "0.001583333",
         "0.003466667",
         "36.14",
         "clear-night",
         "0.62",
         "10.0",
         "Clear",
         "29.26",
         "1016.91",
         "9.18",
         "cloudCover",
         "282",
         "0.0",
         "24.4",
         "0.0"
        ],
        [
         "5",
         "1451624405",
         "1.391866667",
         "0.003433333",
         "1.391866667",
         "0.000283333",
         "0.50325",
         "0.063666667",
         "0.447033333",
         "0.1223",
         "0.006716667",
         "0.012433333",
         "0.000483333",
         "0.000566667",
         "0.0",
         "0.03145",
         "0.001016667",
         "0.004066667",
         "0.001583333",
         "0.003433333",
         "36.14",
         "clear-night",
         "0.62",
         "10.0",
         "Clear",
         "29.26",
         "1016.91",
         "9.18",
         "cloudCover",
         "282",
         "0.0",
         "24.4",
         "0.0"
        ],
        [
         "6",
         "1451624406",
         "1.366216667",
         "0.00345",
         "1.366216667",
         "0.000283333",
         "0.4994",
         "0.063716667",
         "0.443266667",
         "0.12205",
         "0.006733333",
         "0.012416667",
         "0.000516667",
         "0.00055",
         "0.0",
         "0.03155",
         "0.001033333",
         "0.004116667",
         "0.001533333",
         "0.00345",
         "36.14",
         "clear-night",
         "0.62",
         "10.0",
         "Clear",
         "29.26",
         "1016.91",
         "9.18",
         "cloudCover",
         "282",
         "0.0",
         "24.4",
         "0.0"
        ],
        [
         "7",
         "1451624407",
         "1.4319",
         "0.003416667",
         "1.4319",
         "0.00025",
         "0.477866667",
         "0.178633333",
         "0.444283333",
         "0.1218",
         "0.006783333",
         "0.01255",
         "0.000483333",
         "0.00045",
         "0.0",
         "0.031733333",
         "0.001033333",
         "0.0042",
         "0.00155",
         "0.003416667",
         "36.14",
         "clear-night",
         "0.62",
         "10.0",
         "Clear",
         "29.26",
         "1016.91",
         "9.18",
         "cloudCover",
         "282",
         "0.0",
         "24.4",
         "0.0"
        ],
        [
         "8",
         "1451624408",
         "1.6273",
         "0.003416667",
         "1.6273",
         "0.000183333",
         "0.44765",
         "0.3657",
         "0.441466667",
         "0.121616667",
         "0.00695",
         "0.012716667",
         "0.000466667",
         "0.0003",
         "1.67e-05",
         "0.031766667",
         "0.001016667",
         "0.0042",
         "0.001566667",
         "0.003416667",
         "36.14",
         "clear-night",
         "0.62",
         "10.0",
         "Clear",
         "29.26",
         "1016.91",
         "9.18",
         "cloudCover",
         "282",
         "0.0",
         "24.4",
         "0.0"
        ],
        [
         "9",
         "1451624409",
         "1.735383333",
         "0.003416667",
         "1.735383333",
         "1.67e-05",
         "0.17155",
         "0.6825",
         "0.438733333",
         "0.121633333",
         "0.007233333",
         "0.01335",
         "0.000366667",
         "5e-05",
         "0.0",
         "0.031666667",
         "0.001016667",
         "0.0042",
         "0.001616667",
         "0.003416667",
         "36.14",
         "clear-night",
         "0.62",
         "10.0",
         "Clear",
         "29.26",
         "1016.91",
         "9.18",
         "cloudCover",
         "282",
         "0.0",
         "24.4",
         "0.0"
        ],
        [
         "10",
         "1451624410",
         "1.585083333",
         "0.003416667",
         "1.585083333",
         "5e-05",
         "0.0221",
         "0.678733333",
         "0.4402",
         "0.12145",
         "0.007433333",
         "0.013583333",
         "0.00035",
         "0.000116667",
         "3.33e-05",
         "0.031666667",
         "0.001",
         "0.0042",
         "0.001566667",
         "0.003416667",
         "36.14",
         "clear-night",
         "0.62",
         "10.0",
         "Clear",
         "29.26",
         "1016.91",
         "9.18",
         "cloudCover",
         "282",
         "0.0",
         "24.4",
         "0.0"
        ],
        [
         "11",
         "1451624411",
         "1.510316667",
         "0.003433333",
         "1.510316667",
         "3.33e-05",
         "0.021966667",
         "0.620666667",
         "0.43695",
         "0.12125",
         "0.007316667",
         "0.013533333",
         "0.000333333",
         "0.0001",
         "0.0",
         "0.03175",
         "0.001",
         "0.0042",
         "0.001566667",
         "0.003433333",
         "36.14",
         "clear-night",
         "0.62",
         "10.0",
         "Clear",
         "29.26",
         "1016.91",
         "9.18",
         "cloudCover",
         "282",
         "0.0",
         "24.4",
         "0.0"
        ],
        [
         "12",
         "1451624412",
         "1.459866667",
         "0.00345",
         "1.459866667",
         "5e-05",
         "0.021883333",
         "0.577466667",
         "0.43995",
         "0.121033333",
         "0.007233333",
         "0.013516667",
         "0.000366667",
         "8.33e-05",
         "1.67e-05",
         "0.031783333",
         "0.001",
         "0.004216667",
         "0.001583333",
         "0.00345",
         "36.14",
         "clear-night",
         "0.62",
         "10.0",
         "Clear",
         "29.26",
         "1016.91",
         "9.18",
         "cloudCover",
         "282",
         "0.0",
         "24.4",
         "0.0"
        ],
        [
         "13",
         "1451624413",
         "0.840583333",
         "0.003433333",
         "0.840583333",
         "0.0",
         "0.02095",
         "0.1448",
         "0.444783333",
         "0.035016667",
         "0.007033333",
         "0.013183333",
         "0.00065",
         "0.000183333",
         "1.67e-05",
         "0.031783333",
         "0.001016667",
         "0.004216667",
         "0.001616667",
         "0.003433333",
         "36.14",
         "clear-night",
         "0.62",
         "10.0",
         "Clear",
         "29.26",
         "1016.91",
         "9.18",
         "cloudCover",
         "282",
         "0.0",
         "24.4",
         "0.0"
        ],
        [
         "14",
         "1451624414",
         "0.7032",
         "0.003433333",
         "0.7032",
         "1.67e-05",
         "0.020733333",
         "0.061966667",
         "0.443833333",
         "0.004783333",
         "0.006966667",
         "0.013116667",
         "0.000733333",
         "0.000233333",
         "0.0",
         "0.03175",
         "0.001016667",
         "0.004233333",
         "0.00155",
         "0.003433333",
         "36.14",
         "clear-night",
         "0.62",
         "10.0",
         "Clear",
         "29.26",
         "1016.91",
         "9.18",
         "cloudCover",
         "282",
         "0.0",
         "24.4",
         "0.0"
        ],
        [
         "15",
         "1451624415",
         "0.571883333",
         "0.00345",
         "0.571883333",
         "0.0",
         "0.02065",
         "0.06365",
         "0.307783333",
         "0.004916667",
         "0.00705",
         "0.0131",
         "0.000733333",
         "0.00015",
         "0.0",
         "0.031733333",
         "0.001",
         "0.004216667",
         "0.001583333",
         "0.00345",
         "36.14",
         "clear-night",
         "0.62",
         "10.0",
         "Clear",
         "29.26",
         "1016.91",
         "9.18",
         "cloudCover",
         "282",
         "0.0",
         "24.4",
         "0.0"
        ],
        [
         "16",
         "1451624416",
         "0.485733333",
         "0.00345",
         "0.485733333",
         "1.67e-05",
         "0.020616667",
         "0.063433333",
         "0.22045",
         "0.004983333",
         "0.007033333",
         "0.013116667",
         "0.00075",
         "8.33e-05",
         "0.0",
         "0.031833333",
         "0.001",
         "0.004233333",
         "0.001616667",
         "0.00345",
         "36.14",
         "clear-night",
         "0.62",
         "10.0",
         "Clear",
         "29.26",
         "1016.91",
         "9.18",
         "cloudCover",
         "282",
         "0.0",
         "24.4",
         "0.0"
        ],
        [
         "17",
         "1451624417",
         "0.523166667",
         "0.003433333",
         "0.523166667",
         "0.0",
         "0.020633333",
         "0.062116667",
         "0.26005",
         "0.00495",
         "0.007",
         "0.013083333",
         "0.000733333",
         "0.0001",
         "1.67e-05",
         "0.03185",
         "0.001016667",
         "0.00425",
         "0.001716667",
         "0.003433333",
         "36.14",
         "clear-night",
         "0.62",
         "10.0",
         "Clear",
         "29.26",
         "1016.91",
         "9.18",
         "cloudCover",
         "282",
         "0.0",
         "24.4",
         "0.0"
        ],
        [
         "18",
         "1451624418",
         "0.5362",
         "0.00345",
         "0.5362",
         "0.0",
         "0.020683333",
         "0.062916667",
         "0.272066667",
         "0.00495",
         "0.007033333",
         "0.01315",
         "0.000733333",
         "0.000116667",
         "0.0",
         "0.031866667",
         "0.001016667",
         "0.004233333",
         "0.00165",
         "0.00345",
         "36.14",
         "clear-night",
         "0.62",
         "10.0",
         "Clear",
         "29.26",
         "1016.91",
         "9.18",
         "cloudCover",
         "282",
         "0.0",
         "24.4",
         "0.0"
        ],
        [
         "19",
         "1451624419",
         "0.53415",
         "0.00345",
         "0.53415",
         "1.67e-05",
         "0.020666667",
         "0.06265",
         "0.270066667",
         "0.00495",
         "0.0071",
         "0.01315",
         "0.000733333",
         "0.0001",
         "0.0",
         "0.0319",
         "0.001",
         "0.004233333",
         "0.00175",
         "0.00345",
         "36.14",
         "clear-night",
         "0.62",
         "10.0",
         "Clear",
         "29.26",
         "1016.91",
         "9.18",
         "cloudCover",
         "282",
         "0.0",
         "24.4",
         "0.0"
        ],
        [
         "20",
         "1451624420",
         "0.533816667",
         "0.00345",
         "0.533816667",
         "0.0",
         "0.020633333",
         "0.062966667",
         "0.270033333",
         "0.00495",
         "0.007033333",
         "0.013116667",
         "0.00075",
         "0.0001",
         "0.0",
         "0.031816667",
         "0.001016667",
         "0.004233333",
         "0.001566667",
         "0.00345",
         "36.14",
         "clear-night",
         "0.62",
         "10.0",
         "Clear",
         "29.26",
         "1016.91",
         "9.18",
         "cloudCover",
         "282",
         "0.0",
         "24.4",
         "0.0"
        ],
        [
         "21",
         "1451624421",
         "0.523633333",
         "0.00345",
         "0.523633333",
         "1.67e-05",
         "0.02055",
         "0.063283333",
         "0.259816667",
         "0.00495",
         "0.007033333",
         "0.013083333",
         "0.000733333",
         "0.000116667",
         "0.0",
         "0.031733333",
         "0.001016667",
         "0.004216667",
         "0.001666667",
         "0.00345",
         "36.14",
         "clear-night",
         "0.62",
         "10.0",
         "Clear",
         "29.26",
         "1016.91",
         "9.18",
         "cloudCover",
         "282",
         "0.0",
         "24.4",
         "0.0"
        ],
        [
         "22",
         "1451624422",
         "0.57725",
         "0.003416667",
         "0.57725",
         "0.0",
         "0.020683333",
         "0.10975",
         "0.257",
         "0.004983333",
         "0.007066667",
         "0.013133333",
         "0.000733333",
         "8.33e-05",
         "0.0",
         "0.031683333",
         "0.001016667",
         "0.004233333",
         "0.001516667",
         "0.003416667",
         "36.14",
         "clear-night",
         "0.62",
         "10.0",
         "Clear",
         "29.26",
         "1016.91",
         "9.18",
         "cloudCover",
         "282",
         "0.0",
         "24.4",
         "0.0"
        ],
        [
         "23",
         "1451624423",
         "0.679566667",
         "0.003433333",
         "0.679566667",
         "1.67e-05",
         "0.020866667",
         "0.194083333",
         "0.2571",
         "0.005016667",
         "0.007116667",
         "0.0132",
         "0.0007",
         "6.67e-05",
         "1.67e-05",
         "0.031716667",
         "0.001016667",
         "0.004216667",
         "0.00165",
         "0.003433333",
         "36.14",
         "clear-night",
         "0.62",
         "10.0",
         "Clear",
         "29.26",
         "1016.91",
         "9.18",
         "cloudCover",
         "282",
         "0.0",
         "24.4",
         "0.0"
        ],
        [
         "24",
         "1451624424",
         "1.293166667",
         "0.0034",
         "1.293166667",
         "1.67e-05",
         "0.107433333",
         "0.622466667",
         "0.2541",
         "0.0052",
         "0.00725",
         "0.01335",
         "0.00065",
         "0.0001",
         "3.33e-05",
         "0.031566667",
         "0.001",
         "0.0042",
         "0.001566667",
         "0.0034",
         "36.14",
         "clear-night",
         "0.62",
         "10.0",
         "Clear",
         "29.26",
         "1016.91",
         "9.18",
         "cloudCover",
         "282",
         "0.0",
         "24.4",
         "0.0"
        ],
        [
         "25",
         "1451624425",
         "1.546666667",
         "0.003433333",
         "1.546666667",
         "1.67e-05",
         "0.220566667",
         "0.68005",
         "0.253933333",
         "0.00555",
         "0.007266667",
         "0.013183333",
         "0.0007",
         "6.67e-05",
         "1.67e-05",
         "0.031066667",
         "0.001",
         "0.004166667",
         "0.00165",
         "0.003433333",
         "36.14",
         "clear-night",
         "0.62",
         "10.0",
         "Clear",
         "29.26",
         "1016.91",
         "9.18",
         "cloudCover",
         "282",
         "0.0",
         "24.4",
         "0.0"
        ],
        [
         "26",
         "1451624426",
         "1.82235",
         "0.003416667",
         "1.82235",
         "6.67e-05",
         "0.49665",
         "0.677",
         "0.254533333",
         "0.004916667",
         "0.0071",
         "0.012783333",
         "0.000716667",
         "0.000116667",
         "1.67e-05",
         "0.030966667",
         "0.001016667",
         "0.010066667",
         "0.0016",
         "0.003416667",
         "36.14",
         "clear-night",
         "0.62",
         "10.0",
         "Clear",
         "29.26",
         "1016.91",
         "9.18",
         "cloudCover",
         "282",
         "0.0",
         "24.4",
         "0.0"
        ],
        [
         "27",
         "1451624427",
         "2.642516667",
         "0.002033333",
         "2.642516667",
         "8.33e-05",
         "0.49875",
         "0.575566667",
         "0.255533333",
         "0.004566667",
         "0.007033333",
         "0.012666667",
         "0.0004",
         "0.000583333",
         "1.67e-05",
         "0.088066667",
         "0.0015",
         "1.040766667",
         "0.001366667",
         "0.002033333",
         "36.14",
         "clear-night",
         "0.62",
         "10.0",
         "Clear",
         "29.26",
         "1016.91",
         "9.18",
         "cloudCover",
         "282",
         "0.0",
         "24.4",
         "0.0"
        ],
        [
         "28",
         "1451624428",
         "1.73935",
         "0.003133333",
         "1.73935",
         "0.0001",
         "0.49445",
         "0.48835",
         "0.255816667",
         "0.00475",
         "0.007016667",
         "0.012716667",
         "0.000616667",
         "0.000316667",
         "1.67e-05",
         "0.113516667",
         "0.001166667",
         "0.004383333",
         "0.001583333",
         "0.003133333",
         "36.14",
         "clear-night",
         "0.62",
         "10.0",
         "Clear",
         "29.26",
         "1016.91",
         "9.18",
         "cloudCover",
         "282",
         "0.0",
         "24.4",
         "0.0"
        ],
        [
         "29",
         "1451624429",
         "1.1872",
         "0.003083333",
         "1.1872",
         "0.00025",
         "0.453816667",
         "0.062883333",
         "0.256033333",
         "0.004566667",
         "0.024716667",
         "0.0125",
         "0.0007",
         "0.0006",
         "0.0",
         "0.031766667",
         "0.001066667",
         "0.0045",
         "0.001166667",
         "0.003083333",
         "36.14",
         "clear-night",
         "0.62",
         "10.0",
         "Clear",
         "29.26",
         "1016.91",
         "9.18",
         "cloudCover",
         "282",
         "0.0",
         "24.4",
         "0.0"
        ],
        [
         "30",
         "1451624430",
         "1.19095",
         "0.003083333",
         "1.19095",
         "0.000216667",
         "0.3874",
         "0.061883333",
         "0.256866667",
         "0.004933333",
         "0.101783333",
         "0.012533333",
         "0.0007",
         "0.000583333",
         "1.67e-05",
         "0.03175",
         "0.00105",
         "0.0045",
         "0.00115",
         "0.003083333",
         "36.14",
         "clear-night",
         "0.62",
         "10.0",
         "Clear",
         "29.26",
         "1016.91",
         "9.18",
         "cloudCover",
         "282",
         "0.0",
         "24.4",
         "0.0"
        ],
        [
         "31",
         "1451624431",
         "0.833083333",
         "0.003066667",
         "0.833083333",
         "1.67e-05",
         "0.02065",
         "0.063066667",
         "0.254583333",
         "0.004816667",
         "0.097183333",
         "0.013016667",
         "0.000666667",
         "0.000216667",
         "1.67e-05",
         "0.03175",
         "0.001066667",
         "0.0045",
         "0.001166667",
         "0.003066667",
         "36.14",
         "clear-night",
         "0.62",
         "10.0",
         "Clear",
         "29.26",
         "1016.91",
         "9.18",
         "cloudCover",
         "282",
         "0.0",
         "24.4",
         "0.0"
        ],
        [
         "32",
         "1451624432",
         "0.834283333",
         "0.003066667",
         "0.834283333",
         "0.0",
         "0.020616667",
         "0.062033333",
         "0.25655",
         "0.004816667",
         "0.100833333",
         "0.013033333",
         "0.000666667",
         "0.00025",
         "1.67e-05",
         "0.031733333",
         "0.00105",
         "0.004516667",
         "0.0012",
         "0.003066667",
         "36.14",
         "clear-night",
         "0.62",
         "10.0",
         "Clear",
         "29.26",
         "1016.91",
         "9.18",
         "cloudCover",
         "282",
         "0.0",
         "24.4",
         "0.0"
        ],
        [
         "33",
         "1451624433",
         "0.840433333",
         "0.003066667",
         "0.840433333",
         "1.67e-05",
         "0.0206",
         "0.06265",
         "0.256016667",
         "0.004816667",
         "0.10915",
         "0.013033333",
         "0.00065",
         "0.00025",
         "0.0",
         "0.031683333",
         "0.001066667",
         "0.0045",
         "0.001183333",
         "0.003066667",
         "36.14",
         "clear-night",
         "0.62",
         "10.0",
         "Clear",
         "29.26",
         "1016.91",
         "9.18",
         "cloudCover",
         "282",
         "0.0",
         "24.4",
         "0.0"
        ],
        [
         "34",
         "1451624434",
         "0.869733333",
         "0.00305",
         "0.869733333",
         "1.67e-05",
         "0.02055",
         "0.061916667",
         "0.256183333",
         "0.004816667",
         "0.113066667",
         "0.012983333",
         "0.000666667",
         "0.000233333",
         "0.0",
         "0.031833333",
         "0.001066667",
         "0.004533333",
         "0.001233333",
         "0.00305",
         "36.14",
         "clear-night",
         "0.62",
         "10.0",
         "Clear",
         "29.26",
         "1016.91",
         "9.18",
         "cloudCover",
         "282",
         "0.0",
         "24.4",
         "0.0"
        ],
        [
         "35",
         "1451624435",
         "0.853883333",
         "0.00305",
         "0.853883333",
         "0.0",
         "0.020566667",
         "0.063733333",
         "0.2553",
         "0.005216667",
         "0.114266667",
         "0.013",
         "0.000666667",
         "0.00025",
         "0.0",
         "0.03175",
         "0.001066667",
         "0.004516667",
         "0.00115",
         "0.00305",
         "36.14",
         "clear-night",
         "0.62",
         "10.0",
         "Clear",
         "29.26",
         "1016.91",
         "9.18",
         "cloudCover",
         "282",
         "0.0",
         "24.4",
         "0.0"
        ],
        [
         "36",
         "1451624436",
         "0.8491",
         "0.003083333",
         "0.8491",
         "1.67e-05",
         "0.0206",
         "0.063483333",
         "0.256683333",
         "0.004816667",
         "0.116666667",
         "0.013033333",
         "0.000666667",
         "0.00025",
         "1.67e-05",
         "0.0318",
         "0.00105",
         "0.004516667",
         "0.001166667",
         "0.003083333",
         "36.14",
         "clear-night",
         "0.62",
         "10.0",
         "Clear",
         "29.26",
         "1016.91",
         "9.18",
         "cloudCover",
         "282",
         "0.0",
         "24.4",
         "0.0"
        ],
        [
         "37",
         "1451624437",
         "1.013333333",
         "0.00305",
         "1.013333333",
         "0.0",
         "0.020933333",
         "0.198366667",
         "0.2542",
         "0.004883333",
         "0.119133333",
         "0.013116667",
         "0.00065",
         "0.000183333",
         "0.0",
         "0.0317",
         "0.001066667",
         "0.0045",
         "0.001216667",
         "0.00305",
         "36.14",
         "clear-night",
         "0.62",
         "10.0",
         "Clear",
         "29.26",
         "1016.91",
         "9.18",
         "cloudCover",
         "282",
         "0.0",
         "24.4",
         "0.0"
        ],
        [
         "38",
         "1451624438",
         "1.3159",
         "0.003033333",
         "1.3159",
         "1.67e-05",
         "0.0214",
         "0.415216667",
         "0.2478",
         "0.004983333",
         "0.120566667",
         "0.013316667",
         "0.000583333",
         "0.0001",
         "1.67e-05",
         "0.086216667",
         "0.00115",
         "0.00445",
         "0.00135",
         "0.003033333",
         "36.14",
         "clear-night",
         "0.62",
         "10.0",
         "Clear",
         "29.26",
         "1016.91",
         "9.18",
         "cloudCover",
         "282",
         "0.0",
         "24.4",
         "0.0"
        ],
        [
         "39",
         "1451624439",
         "1.654516667",
         "0.00305",
         "1.654516667",
         "6.67e-05",
         "0.022033333",
         "0.680333333",
         "0.23785",
         "0.005116667",
         "0.122116667",
         "0.01355",
         "0.00055",
         "1.67e-05",
         "1.67e-05",
         "0.119366667",
         "0.0012",
         "0.00445",
         "0.001483333",
         "0.00305",
         "36.14",
         "clear-night",
         "0.62",
         "10.0",
         "Clear",
         "29.26",
         "1016.91",
         "9.18",
         "cloudCover",
         "282",
         "0.0",
         "24.4",
         "0.0"
        ],
        [
         "40",
         "1451624440",
         "1.582083333",
         "0.003066667",
         "1.582083333",
         "5e-05",
         "0.02205",
         "0.681716667",
         "0.242433333",
         "0.00555",
         "0.1224",
         "0.01355",
         "0.000566667",
         "1.67e-05",
         "3.33e-05",
         "0.031666667",
         "0.001083333",
         "0.004483333",
         "0.001166667",
         "0.003066667",
         "36.14",
         "clear-night",
         "0.62",
         "10.0",
         "Clear",
         "29.26",
         "1016.91",
         "9.18",
         "cloudCover",
         "282",
         "0.0",
         "24.4",
         "0.0"
        ],
        [
         "41",
         "1451624441",
         "1.440416667",
         "0.0032",
         "1.440416667",
         "5e-05",
         "0.0219",
         "0.618516667",
         "0.246733333",
         "0.005133333",
         "0.122366667",
         "0.013483333",
         "0.000616667",
         "3.33e-05",
         "0.0",
         "0.03155",
         "0.00105",
         "0.004383333",
         "0.001383333",
         "0.0032",
         "36.14",
         "clear-night",
         "0.62",
         "10.0",
         "Clear",
         "29.26",
         "1016.91",
         "9.18",
         "cloudCover",
         "282",
         "0.0",
         "24.4",
         "0.0"
        ],
        [
         "42",
         "1451624442",
         "1.42185",
         "0.00305",
         "1.42185",
         "3.33e-05",
         "0.021783333",
         "0.592583333",
         "0.202433333",
         "0.005133333",
         "0.122",
         "0.013433333",
         "0.000583333",
         "1.67e-05",
         "1.67e-05",
         "0.0316",
         "0.001066667",
         "0.004483333",
         "0.001216667",
         "0.00305",
         "36.14",
         "clear-night",
         "0.62",
         "10.0",
         "Clear",
         "29.26",
         "1016.91",
         "9.18",
         "cloudCover",
         "282",
         "0.0",
         "24.4",
         "0.0"
        ],
        [
         "43",
         "1451624443",
         "0.7322",
         "0.00305",
         "0.7322",
         "1.67e-05",
         "0.020733333",
         "0.142666667",
         "0.043333333",
         "0.0408",
         "0.122133333",
         "0.013083333",
         "0.000566667",
         "1.67e-05",
         "0.0",
         "0.031883333",
         "0.001016667",
         "0.0045",
         "0.001216667",
         "0.00305",
         "36.14",
         "clear-night",
         "0.62",
         "10.0",
         "Clear",
         "29.26",
         "1016.91",
         "9.18",
         "cloudCover",
         "282",
         "0.0",
         "24.4",
         "0.0"
        ],
        [
         "44",
         "1451624444",
         "0.523216667",
         "0.003366667",
         "0.523216667",
         "1.67e-05",
         "0.086866667",
         "0.062966667",
         "0.043383333",
         "0.005",
         "0.122116667",
         "0.012933333",
         "0.000716667",
         "8.33e-05",
         "1.67e-05",
         "0.03185",
         "0.001033333",
         "0.0043",
         "0.001516667",
         "0.003366667",
         "36.14",
         "clear-night",
         "0.62",
         "10.0",
         "Clear",
         "29.26",
         "1016.91",
         "9.18",
         "cloudCover",
         "282",
         "0.0",
         "24.4",
         "0.0"
        ],
        [
         "45",
         "1451624445",
         "0.50875",
         "0.00335",
         "0.50875",
         "0.0",
         "0.064783333",
         "0.064533333",
         "0.043383333",
         "0.005",
         "0.122316667",
         "0.013",
         "0.000716667",
         "6.67e-05",
         "0.0",
         "0.03185",
         "0.001016667",
         "0.0043",
         "0.001516667",
         "0.00335",
         "36.14",
         "clear-night",
         "0.62",
         "10.0",
         "Clear",
         "29.26",
         "1016.91",
         "9.18",
         "cloudCover",
         "282",
         "0.0",
         "24.4",
         "0.0"
        ],
        [
         "46",
         "1451624446",
         "0.613583333",
         "0.003333333",
         "0.613583333",
         "3.33e-05",
         "0.11965",
         "0.0639",
         "0.043416667",
         "0.00495",
         "0.122266667",
         "0.01285",
         "0.0007",
         "0.000133333",
         "0.0",
         "0.03415",
         "0.001016667",
         "0.004316667",
         "0.0015",
         "0.003333333",
         "36.14",
         "clear-night",
         "0.62",
         "10.0",
         "Clear",
         "29.26",
         "1016.91",
         "9.18",
         "cloudCover",
         "282",
         "0.0",
         "24.4",
         "0.0"
        ],
        [
         "47",
         "1451624447",
         "0.917666667",
         "0.00335",
         "0.917666667",
         "0.000133333",
         "0.311366667",
         "0.063033333",
         "0.0436",
         "0.004766667",
         "0.12215",
         "0.0126",
         "0.000683333",
         "0.000333333",
         "0.0",
         "0.17555",
         "0.00125",
         "0.00425",
         "0.001833333",
         "0.00335",
         "36.14",
         "clear-night",
         "0.62",
         "10.0",
         "Clear",
         "29.26",
         "1016.91",
         "9.18",
         "cloudCover",
         "282",
         "0.0",
         "24.4",
         "0.0"
        ],
        [
         "48",
         "1451624448",
         "0.9594",
         "0.003366667",
         "0.9594",
         "0.000266667",
         "0.500116667",
         "0.06225",
         "0.043666667",
         "0.00465",
         "0.12225",
         "0.012333333",
         "0.000716667",
         "0.000466667",
         "1.67e-05",
         "0.036783333",
         "0.001016667",
         "0.004266667",
         "0.001483333",
         "0.003366667",
         "36.14",
         "clear-night",
         "0.62",
         "10.0",
         "Clear",
         "29.26",
         "1016.91",
         "9.18",
         "cloudCover",
         "282",
         "0.0",
         "24.4",
         "0.0"
        ],
        [
         "49",
         "1451624449",
         "0.918633333",
         "0.003383333",
         "0.918633333",
         "0.000266667",
         "0.47045",
         "0.062633333",
         "0.043716667",
         "0.004683333",
         "0.1223",
         "0.0124",
         "0.000783333",
         "0.000416667",
         "0.0",
         "0.031633333",
         "0.001033333",
         "0.004266667",
         "0.001466667",
         "0.003383333",
         "36.14",
         "clear-night",
         "0.62",
         "10.0",
         "Clear",
         "29.26",
         "1016.91",
         "9.18",
         "cloudCover",
         "282",
         "0.0",
         "24.4",
         "0.0"
        ]
       ],
       "shape": {
        "columns": 32,
        "rows": 503910
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>use [kW]</th>\n",
       "      <th>gen [kW]</th>\n",
       "      <th>House overall [kW]</th>\n",
       "      <th>Dishwasher [kW]</th>\n",
       "      <th>Furnace 1 [kW]</th>\n",
       "      <th>Furnace 2 [kW]</th>\n",
       "      <th>Home office [kW]</th>\n",
       "      <th>Fridge [kW]</th>\n",
       "      <th>Wine cellar [kW]</th>\n",
       "      <th>...</th>\n",
       "      <th>visibility</th>\n",
       "      <th>summary</th>\n",
       "      <th>apparentTemperature</th>\n",
       "      <th>pressure</th>\n",
       "      <th>windSpeed</th>\n",
       "      <th>cloudCover</th>\n",
       "      <th>windBearing</th>\n",
       "      <th>precipIntensity</th>\n",
       "      <th>dewPoint</th>\n",
       "      <th>precipProbability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1451624400</td>\n",
       "      <td>0.932833</td>\n",
       "      <td>0.003483</td>\n",
       "      <td>0.932833</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.020700</td>\n",
       "      <td>0.061917</td>\n",
       "      <td>0.442633</td>\n",
       "      <td>0.124150</td>\n",
       "      <td>0.006983</td>\n",
       "      <td>...</td>\n",
       "      <td>10.00</td>\n",
       "      <td>Clear</td>\n",
       "      <td>29.26</td>\n",
       "      <td>1016.91</td>\n",
       "      <td>9.18</td>\n",
       "      <td>cloudCover</td>\n",
       "      <td>282</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>24.40</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1451624401</td>\n",
       "      <td>0.934333</td>\n",
       "      <td>0.003467</td>\n",
       "      <td>0.934333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020717</td>\n",
       "      <td>0.063817</td>\n",
       "      <td>0.444067</td>\n",
       "      <td>0.124000</td>\n",
       "      <td>0.006983</td>\n",
       "      <td>...</td>\n",
       "      <td>10.00</td>\n",
       "      <td>Clear</td>\n",
       "      <td>29.26</td>\n",
       "      <td>1016.91</td>\n",
       "      <td>9.18</td>\n",
       "      <td>cloudCover</td>\n",
       "      <td>282</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>24.40</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1451624402</td>\n",
       "      <td>0.931817</td>\n",
       "      <td>0.003467</td>\n",
       "      <td>0.931817</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.020700</td>\n",
       "      <td>0.062317</td>\n",
       "      <td>0.446067</td>\n",
       "      <td>0.123533</td>\n",
       "      <td>0.006983</td>\n",
       "      <td>...</td>\n",
       "      <td>10.00</td>\n",
       "      <td>Clear</td>\n",
       "      <td>29.26</td>\n",
       "      <td>1016.91</td>\n",
       "      <td>9.18</td>\n",
       "      <td>cloudCover</td>\n",
       "      <td>282</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>24.40</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1451624403</td>\n",
       "      <td>1.022050</td>\n",
       "      <td>0.003483</td>\n",
       "      <td>1.022050</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.106900</td>\n",
       "      <td>0.068517</td>\n",
       "      <td>0.446583</td>\n",
       "      <td>0.123133</td>\n",
       "      <td>0.006983</td>\n",
       "      <td>...</td>\n",
       "      <td>10.00</td>\n",
       "      <td>Clear</td>\n",
       "      <td>29.26</td>\n",
       "      <td>1016.91</td>\n",
       "      <td>9.18</td>\n",
       "      <td>cloudCover</td>\n",
       "      <td>282</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>24.40</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1451624404</td>\n",
       "      <td>1.139400</td>\n",
       "      <td>0.003467</td>\n",
       "      <td>1.139400</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.236933</td>\n",
       "      <td>0.063983</td>\n",
       "      <td>0.446533</td>\n",
       "      <td>0.122850</td>\n",
       "      <td>0.006850</td>\n",
       "      <td>...</td>\n",
       "      <td>10.00</td>\n",
       "      <td>Clear</td>\n",
       "      <td>29.26</td>\n",
       "      <td>1016.91</td>\n",
       "      <td>9.18</td>\n",
       "      <td>cloudCover</td>\n",
       "      <td>282</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>24.40</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503905</th>\n",
       "      <td>1452128305</td>\n",
       "      <td>1.601233</td>\n",
       "      <td>0.003183</td>\n",
       "      <td>1.601233</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.085267</td>\n",
       "      <td>0.642417</td>\n",
       "      <td>0.041783</td>\n",
       "      <td>0.005267</td>\n",
       "      <td>0.008667</td>\n",
       "      <td>...</td>\n",
       "      <td>8.74</td>\n",
       "      <td>Light Rain</td>\n",
       "      <td>29.45</td>\n",
       "      <td>1011.49</td>\n",
       "      <td>6.72</td>\n",
       "      <td>0.31</td>\n",
       "      <td>186</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>31.27</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503906</th>\n",
       "      <td>1452128306</td>\n",
       "      <td>1.599333</td>\n",
       "      <td>0.003233</td>\n",
       "      <td>1.599333</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.104017</td>\n",
       "      <td>0.625033</td>\n",
       "      <td>0.041750</td>\n",
       "      <td>0.005233</td>\n",
       "      <td>0.008433</td>\n",
       "      <td>...</td>\n",
       "      <td>8.74</td>\n",
       "      <td>Light Rain</td>\n",
       "      <td>29.45</td>\n",
       "      <td>1011.49</td>\n",
       "      <td>6.72</td>\n",
       "      <td>0.31</td>\n",
       "      <td>186</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>31.27</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503907</th>\n",
       "      <td>1452128307</td>\n",
       "      <td>1.924267</td>\n",
       "      <td>0.003217</td>\n",
       "      <td>1.924267</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.422383</td>\n",
       "      <td>0.637733</td>\n",
       "      <td>0.042033</td>\n",
       "      <td>0.004983</td>\n",
       "      <td>0.008467</td>\n",
       "      <td>...</td>\n",
       "      <td>8.74</td>\n",
       "      <td>Light Rain</td>\n",
       "      <td>29.45</td>\n",
       "      <td>1011.49</td>\n",
       "      <td>6.72</td>\n",
       "      <td>0.31</td>\n",
       "      <td>186</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>31.27</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503908</th>\n",
       "      <td>1452128308</td>\n",
       "      <td>1.978200</td>\n",
       "      <td>0.003217</td>\n",
       "      <td>1.978200</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.495667</td>\n",
       "      <td>0.620367</td>\n",
       "      <td>0.042100</td>\n",
       "      <td>0.005333</td>\n",
       "      <td>0.008233</td>\n",
       "      <td>...</td>\n",
       "      <td>8.74</td>\n",
       "      <td>Light Rain</td>\n",
       "      <td>29.45</td>\n",
       "      <td>1011.49</td>\n",
       "      <td>6.72</td>\n",
       "      <td>0.31</td>\n",
       "      <td>186</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>31.27</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503909</th>\n",
       "      <td>1452128309</td>\n",
       "      <td>1.990950</td>\n",
       "      <td>0.003233</td>\n",
       "      <td>1.990950</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.494700</td>\n",
       "      <td>0.634133</td>\n",
       "      <td>0.042100</td>\n",
       "      <td>0.004917</td>\n",
       "      <td>0.008133</td>\n",
       "      <td>...</td>\n",
       "      <td>8.74</td>\n",
       "      <td>Light Rain</td>\n",
       "      <td>29.45</td>\n",
       "      <td>1011.49</td>\n",
       "      <td>6.72</td>\n",
       "      <td>0.31</td>\n",
       "      <td>186</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>31.27</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>503910 rows  32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              time  use [kW]  gen [kW]  House overall [kW]  Dishwasher [kW]  \\\n",
       "0       1451624400  0.932833  0.003483            0.932833         0.000033   \n",
       "1       1451624401  0.934333  0.003467            0.934333         0.000000   \n",
       "2       1451624402  0.931817  0.003467            0.931817         0.000017   \n",
       "3       1451624403  1.022050  0.003483            1.022050         0.000017   \n",
       "4       1451624404  1.139400  0.003467            1.139400         0.000133   \n",
       "...            ...       ...       ...                 ...              ...   \n",
       "503905  1452128305  1.601233  0.003183            1.601233         0.000050   \n",
       "503906  1452128306  1.599333  0.003233            1.599333         0.000050   \n",
       "503907  1452128307  1.924267  0.003217            1.924267         0.000033   \n",
       "503908  1452128308  1.978200  0.003217            1.978200         0.000050   \n",
       "503909  1452128309  1.990950  0.003233            1.990950         0.000050   \n",
       "\n",
       "        Furnace 1 [kW]  Furnace 2 [kW]  Home office [kW]  Fridge [kW]  \\\n",
       "0             0.020700        0.061917          0.442633     0.124150   \n",
       "1             0.020717        0.063817          0.444067     0.124000   \n",
       "2             0.020700        0.062317          0.446067     0.123533   \n",
       "3             0.106900        0.068517          0.446583     0.123133   \n",
       "4             0.236933        0.063983          0.446533     0.122850   \n",
       "...                ...             ...               ...          ...   \n",
       "503905        0.085267        0.642417          0.041783     0.005267   \n",
       "503906        0.104017        0.625033          0.041750     0.005233   \n",
       "503907        0.422383        0.637733          0.042033     0.004983   \n",
       "503908        0.495667        0.620367          0.042100     0.005333   \n",
       "503909        0.494700        0.634133          0.042100     0.004917   \n",
       "\n",
       "        Wine cellar [kW]  ...  visibility     summary  apparentTemperature  \\\n",
       "0               0.006983  ...       10.00       Clear                29.26   \n",
       "1               0.006983  ...       10.00       Clear                29.26   \n",
       "2               0.006983  ...       10.00       Clear                29.26   \n",
       "3               0.006983  ...       10.00       Clear                29.26   \n",
       "4               0.006850  ...       10.00       Clear                29.26   \n",
       "...                  ...  ...         ...         ...                  ...   \n",
       "503905          0.008667  ...        8.74  Light Rain                29.45   \n",
       "503906          0.008433  ...        8.74  Light Rain                29.45   \n",
       "503907          0.008467  ...        8.74  Light Rain                29.45   \n",
       "503908          0.008233  ...        8.74  Light Rain                29.45   \n",
       "503909          0.008133  ...        8.74  Light Rain                29.45   \n",
       "\n",
       "        pressure  windSpeed  cloudCover  windBearing  precipIntensity  \\\n",
       "0        1016.91       9.18  cloudCover          282           0.0000   \n",
       "1        1016.91       9.18  cloudCover          282           0.0000   \n",
       "2        1016.91       9.18  cloudCover          282           0.0000   \n",
       "3        1016.91       9.18  cloudCover          282           0.0000   \n",
       "4        1016.91       9.18  cloudCover          282           0.0000   \n",
       "...          ...        ...         ...          ...              ...   \n",
       "503905   1011.49       6.72        0.31          186           0.0101   \n",
       "503906   1011.49       6.72        0.31          186           0.0101   \n",
       "503907   1011.49       6.72        0.31          186           0.0101   \n",
       "503908   1011.49       6.72        0.31          186           0.0101   \n",
       "503909   1011.49       6.72        0.31          186           0.0101   \n",
       "\n",
       "        dewPoint  precipProbability  \n",
       "0          24.40               0.00  \n",
       "1          24.40               0.00  \n",
       "2          24.40               0.00  \n",
       "3          24.40               0.00  \n",
       "4          24.40               0.00  \n",
       "...          ...                ...  \n",
       "503905     31.27               0.51  \n",
       "503906     31.27               0.51  \n",
       "503907     31.27               0.51  \n",
       "503908     31.27               0.51  \n",
       "503909     31.27               0.51  \n",
       "\n",
       "[503910 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 503910 entries, 0 to 503909\n",
      "Data columns (total 32 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   time                 503910 non-null  int64  \n",
      " 1   use [kW]             503910 non-null  float64\n",
      " 2   gen [kW]             503910 non-null  float64\n",
      " 3   House overall [kW]   503910 non-null  float64\n",
      " 4   Dishwasher [kW]      503910 non-null  float64\n",
      " 5   Furnace 1 [kW]       503910 non-null  float64\n",
      " 6   Furnace 2 [kW]       503910 non-null  float64\n",
      " 7   Home office [kW]     503910 non-null  float64\n",
      " 8   Fridge [kW]          503910 non-null  float64\n",
      " 9   Wine cellar [kW]     503910 non-null  float64\n",
      " 10  Garage door [kW]     503910 non-null  float64\n",
      " 11  Kitchen 12 [kW]      503910 non-null  float64\n",
      " 12  Kitchen 14 [kW]      503910 non-null  float64\n",
      " 13  Kitchen 38 [kW]      503910 non-null  float64\n",
      " 14  Barn [kW]            503910 non-null  float64\n",
      " 15  Well [kW]            503910 non-null  float64\n",
      " 16  Microwave [kW]       503910 non-null  float64\n",
      " 17  Living room [kW]     503910 non-null  float64\n",
      " 18  Solar [kW]           503910 non-null  float64\n",
      " 19  temperature          503910 non-null  float64\n",
      " 20  icon                 503910 non-null  object \n",
      " 21  humidity             503910 non-null  float64\n",
      " 22  visibility           503910 non-null  float64\n",
      " 23  summary              503910 non-null  object \n",
      " 24  apparentTemperature  503910 non-null  float64\n",
      " 25  pressure             503910 non-null  float64\n",
      " 26  windSpeed            503910 non-null  float64\n",
      " 27  cloudCover           503910 non-null  object \n",
      " 28  windBearing          503910 non-null  int64  \n",
      " 29  precipIntensity      503910 non-null  float64\n",
      " 30  dewPoint             503910 non-null  float64\n",
      " 31  precipProbability    503910 non-null  float64\n",
      "dtypes: float64(27), int64(2), object(3)\n",
      "memory usage: 123.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in the dataset\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing Values:\\n\", missing_values[missing_values > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the data types of each column\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for unique values in columns that should be numeric\n",
    "for column in df.columns:\n",
    "    if df[column].dtype == 'object':\n",
    "        print(f\"Unique values in '{column}':\\n\", df[column].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with NaN values if necessary\n",
    "df.dropna(inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "cloud_cover_index = df[df['cloudCover'] == \"cloudCover\"].index\n",
    "df.drop(cloud_cover_index, inplace=True)\n",
    "df['cloudCover'] = df['cloudCover'].astype(float)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode 'icon' and 'summary' columns\n",
    "icon_one_hot = pd.get_dummies(df['icon'], prefix='icon', drop_first=True)\n",
    "summary_one_hot = pd.get_dummies(df['summary'], prefix='summary', drop_first=True)\n",
    "\n",
    "columns_to_drop = ['icon', 'summary']\n",
    "dropped_columns_df = df[columns_to_drop]\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = df.corr()\n",
    "\n",
    "# Plot the correlation heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True,\n",
    "            fmt=\".2f\", cmap='coolwarm', square=True)\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate moving average\n",
    "df['moving_average'] = df['House overall [kW]'].rolling(window=60*60).mean()\n",
    "df['std_dev'] = df['House overall [kW]'].rolling(window=60*60).std()\n",
    "\n",
    "# Define upper and lower thresholds\n",
    "df['upper_threshold'] = df['moving_average'] + (2 * df['std_dev'])\n",
    "df['lower_threshold'] = df['moving_average'] - (2 * df['std_dev'])\n",
    "\n",
    "# Initialize the anomaly flag\n",
    "df['anomaly_flag'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flag anomalies\n",
    "df.loc[df['House overall [kW]'] > df['upper_threshold'], 'anomaly_flag'] = 1\n",
    "df.loc[df['House overall [kW]'] < df['lower_threshold'], 'anomaly_flag'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with NaN values\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_column = ['anomaly_flag', 'use [kW]',\n",
    "                   'temperature', 'humidity', 'pressure', 'windSpeed', 'cloudCover', 'windBearing', 'precipIntensity', 'precipProbability']\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = df[selected_column].corr()\n",
    "\n",
    "# Plot the correlation heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True,\n",
    "            fmt=\".2f\", cmap='coolwarm', square=True)\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['temperature', 'humidity', 'pressure', 'windSpeed',\n",
    "        'cloudCover', 'windBearing', 'precipIntensity', 'precipProbability']]\n",
    "y = df['anomaly_flag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTETomek to balance the training set\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "smt = SMOTETomek(sampling_strategy=0.5, random_state=42)\n",
    "X_train_resampled, y_train_resampled = smt.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train_resampled)\n",
    "X_test = scaler.transform(X_test)\n",
    "y_train = y_train_resampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionScratchMSE:\n",
    "    def __init__(self, learning_rate=0.01, num_iterations=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_iterations = num_iterations\n",
    "        self.w = None\n",
    "        self.b = None\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def predict(self, X):\n",
    "        z = np.dot(X, self.w) + self.b\n",
    "        probs = self.sigmoid(z)\n",
    "\n",
    "        # Return the class with the highest probability\n",
    "        return np.where(probs >= 0.5, 1, 0)\n",
    "\n",
    "    def initialize_weights(self, n_features):\n",
    "        # Init with the same column number as feature\n",
    "        self.w = np.zeros((n_features, 1))\n",
    "        self.b = 0\n",
    "\n",
    "    def cost_function(self, h, y):\n",
    "        m = len(y)\n",
    "        # reg_term = (0.01 / (2 * m)) * np.sum(self.w ** 2)\n",
    "        cost = (1/m) * np.sum((h - y)**2)\n",
    "\n",
    "        return cost  # + reg_term\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y).reshape(-1, 1)  # Ensure y is a column vector\n",
    "        print(X.shape, y.shape)\n",
    "        m = len(y)\n",
    "        n_features = X.shape[1]\n",
    "        self.initialize_weights(n_features)\n",
    "\n",
    "        for i in range(self.num_iterations):\n",
    "            # Forward prop\n",
    "            probs = self.predict(X)\n",
    "\n",
    "            # Cost\n",
    "            # error = -(1 / m) * np.sum(y * np.log(probs + 1e-8) + (1 - y) * np.log(1 - probs + 1e-8))\n",
    "            error = self.cost_function(probs, y)\n",
    "\n",
    "            # Calculate the gradient of the error with respect to the weights\n",
    "            gradient_w = (1 / m) * np.dot(X.T, (probs - y))\n",
    "            gradient_b = (1 / m) * np.sum(probs - y)\n",
    "\n",
    "            # Update the weights using the gradient and the learning rate\n",
    "            self.w -= self.learning_rate * gradient_w\n",
    "            self.b -= self.learning_rate * gradient_b\n",
    "\n",
    "            # cost compute if more iteration (optional)\n",
    "            if i % 100 == 0:\n",
    "                print(f\"Iteration {i}, Cost: {error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scikit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Logistic Regression\n",
    "log_model = LogisticRegression()\n",
    "log_model.fit(X_train, y_train)\n",
    "y_pred_log = log_model.predict(X_test)\n",
    "print(\"Logistic Regression Report:\\n\",\n",
    "      classification_report(y_test, y_pred_log))\n",
    "joblib.dump(log_model, \"models/logisitic_regression_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(log_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionNode:\n",
    "    def __init__(self, impurity=None, feature_index=None, threshold=None, left=None, right=None):\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        # The largest impurity value of this node\n",
    "        self.impurity = impurity\n",
    "        # Index of the feature which make the best fit for this node.\n",
    "        self.feature_index = feature_index\n",
    "        # The threshold value for that feature to make the split.\n",
    "        self.threshold = threshold\n",
    "\n",
    "\n",
    "class LeafNode:\n",
    "    def __init__(self, value):\n",
    "        self.prediction_value = value\n",
    "\n",
    "\n",
    "class DecisionTreeClassifierFromScratch:\n",
    "    def __init__(self, min_sample_split=3, min_impurity=1e-7, max_depth=10, criterion='gini'):\n",
    "        self.root = None\n",
    "        self.min_sample_split = min_sample_split\n",
    "        self.min_impurity = min_impurity\n",
    "        self.max_depth = max_depth\n",
    "        self.impurity_function = self._calculate_information_gain\n",
    "        if criterion == 'entropy':\n",
    "            self.criterion = self._entropy\n",
    "            self.criterion_name = criterion\n",
    "        else:\n",
    "            self.criterion = self._gini_index\n",
    "            self.criterion_name = 'gini'\n",
    "\n",
    "    def _gini_index(self, y):\n",
    "        gini = 1\n",
    "        unique_value = np.unique(y)\n",
    "        for val in unique_value:\n",
    "            # probability of that class.\n",
    "            p = np.sum(y == val) / len(y)\n",
    "            gini += -np.square(p)\n",
    "        return gini\n",
    "\n",
    "    def _entropy(self, y):\n",
    "        entropy = 0\n",
    "        unique_value = np.unique(y)\n",
    "        for val in unique_value:\n",
    "            # probability of that class.\n",
    "            p = np.sum(y == val) / len(y)\n",
    "            entropy += -p * np.log2(p)\n",
    "        return entropy\n",
    "\n",
    "    def _calculate_information_gain(self, y, y1, y2):\n",
    "        # :param y: target value.\n",
    "        # :param y1: target value for dataset in the true split/right branch.\n",
    "        # :param y2: target value for dataset in the false split/left branch.\n",
    "\n",
    "        # propobility of true values.\n",
    "        p = len(y1) / len(y)\n",
    "        info_gain = self.criterion(\n",
    "            y) - p * self.criterion(y1) - (1 - p) * self.criterion(y2)\n",
    "        return info_gain\n",
    "\n",
    "    def _leaf_value_calculation(self, y):\n",
    "        most_frequent_label = None\n",
    "        max_count = 0\n",
    "        unique_labels = np.unique(y)\n",
    "        # iterate over all the unique values and find their frequentcy count.\n",
    "        for label in unique_labels:\n",
    "            count = len(y[y == label])\n",
    "            if count > max_count:\n",
    "                most_frequent_label = label\n",
    "                max_count = count\n",
    "        return most_frequent_label\n",
    "\n",
    "    def _partition_dataset(self, Xy, feature_index, threshold):\n",
    "        col = Xy[:, feature_index]\n",
    "        X_1 = Xy[col >= threshold]\n",
    "        X_2 = Xy[col < threshold]\n",
    "\n",
    "        return X_1, X_2\n",
    "\n",
    "    def _find_best_split(self, Xy):\n",
    "        best_question = tuple()\n",
    "        best_datasplit = {}\n",
    "        largest_impurity = 0\n",
    "        n_features = (Xy.shape[1] - 1)\n",
    "        # iterate over all the features.\n",
    "        for feature_index in range(n_features):\n",
    "            # find the unique values in that feature.\n",
    "            unique_value = set(s for s in Xy[:, feature_index])\n",
    "            # iterate over all the unique values to find the impurity.\n",
    "            for threshold in unique_value:\n",
    "                # split the dataset based on the feature value.\n",
    "                true_xy, false_xy = self._partition_dataset(\n",
    "                    Xy, feature_index, threshold)\n",
    "\n",
    "                # skip the node which has any on type 0. because this means it is already pure.\n",
    "                if len(true_xy) > 0 and len(false_xy) > 0:\n",
    "                    # find the y values.\n",
    "                    y = Xy[:, -1]\n",
    "                    true_y = true_xy[:, -1]\n",
    "                    false_y = false_xy[:, -1]\n",
    "                    # calculate the impurity function.\n",
    "                    impurity = self.impurity_function(y, true_y, false_y)\n",
    "\n",
    "                    # if the calculated impurity is larger than save this value for comaparison (highest gain).\n",
    "                    if impurity > largest_impurity:\n",
    "                        largest_impurity = impurity\n",
    "                        best_question = (feature_index, threshold)\n",
    "                        best_datasplit = {\n",
    "                            # X of left subtree\n",
    "                            \"leftX\": true_xy[:, :n_features],\n",
    "                            # y of left subtree\n",
    "                            \"lefty\": true_xy[:, n_features:],\n",
    "                            # X of right subtree\n",
    "                            \"rightX\": false_xy[:, :n_features],\n",
    "                            # y of right subtree\n",
    "                            \"righty\": false_xy[:, n_features:]\n",
    "                        }\n",
    "\n",
    "        return largest_impurity, best_question, best_datasplit\n",
    "\n",
    "    def _build_tree(self, X, y, current_depth=0):\n",
    "        n_samples, n_features = X.shape\n",
    "        # Add y as last column of X\n",
    "        Xy = np.column_stack((X, y))\n",
    "        # find the Information gain on each feature each values and return the question which splits the data very well\n",
    "        if (n_samples >= self.min_sample_split) and (current_depth < self.max_depth):\n",
    "            # find the best split/ which question split the data well.\n",
    "            impurity, quesion, best_datasplit = self._find_best_split(Xy)\n",
    "            if impurity > self.min_impurity:\n",
    "                # Build subtrees for the right and left branch.\n",
    "                true_branch = self._build_tree(\n",
    "                    best_datasplit[\"leftX\"], best_datasplit[\"lefty\"], current_depth + 1)\n",
    "                false_branch = self._build_tree(\n",
    "                    best_datasplit[\"rightX\"], best_datasplit[\"righty\"], current_depth + 1)\n",
    "                return DecisionNode(impurity=impurity, feature_index=quesion[0], threshold=quesion[1],\n",
    "                                    left=true_branch, right=false_branch)\n",
    "\n",
    "        leaf_value = self._leaf_value_calculation(y)\n",
    "        return LeafNode(value=leaf_value)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.root = self._build_tree(X, y, current_depth=0)\n",
    "\n",
    "    def predict_sample(self, x, tree=None):\n",
    "        if isinstance(tree, LeafNode):\n",
    "            return tree.prediction_value\n",
    "\n",
    "        if tree is None:\n",
    "            tree = self.root\n",
    "        feature_value = x[tree.feature_index]\n",
    "        branch = tree.right\n",
    "\n",
    "        if isinstance(feature_value, int) or isinstance(feature_value, float):\n",
    "            if feature_value >= tree.threshold:\n",
    "                branch = tree.left\n",
    "        elif feature_value == tree.threshold:\n",
    "            branch = tree.left\n",
    "\n",
    "        return self.predict_sample(x, branch)\n",
    "\n",
    "    def predict(self, test_X):\n",
    "        x = np.array(test_X)\n",
    "        y_pred = [self.predict_sample(sample) for sample in x]\n",
    "        y_pred = np.array(y_pred)\n",
    "        return y_pred\n",
    "\n",
    "    def draw_tree(self):\n",
    "        self._draw_tree(self.root)\n",
    "\n",
    "    def _draw_tree(self, tree=None, indentation=\" \", depth=0):\n",
    "        if isinstance(tree, LeafNode):\n",
    "            print(indentation, \"The predicted value -->\", tree.prediction_value)\n",
    "            return\n",
    "        else:\n",
    "            print(indentation, f\"({depth}) Is {tree.feature_index}>={tree.threshold}?\"\n",
    "                  f\": {self.criterion_name}:{tree.impurity:.2f}\")\n",
    "            if tree.left is not None:\n",
    "                print(indentation + '----- True branch :)')\n",
    "                self._draw_tree(tree.left, indentation + \"  \", depth+1)\n",
    "            if tree.right is not None:\n",
    "                print(indentation + '----- False branch :)')\n",
    "                self._draw_tree(tree.right, indentation + \"  \", depth+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scikit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Decision Tree\n",
    "tree_model = DecisionTreeClassifier()\n",
    "tree_model.fit(X_train, y_train)\n",
    "y_pred_tree = tree_model.predict(X_test)\n",
    "print(\"Decision Tree Report:\\n\", classification_report(y_test, y_pred_tree))\n",
    "joblib.dump(tree_model, 'models/decision_tree_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(tree_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scikit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM_Linear_Scratch:\n",
    "    def __init__(self, C=1, batch_size=100, learning_rate=0.001, iterations=1000):\n",
    "        # C = error term\n",
    "        self.C = C\n",
    "        self.batch_size = batch_size\n",
    "        self.iterations = iterations\n",
    "        self.learning_rate = learning_rate\n",
    "        self.w = None\n",
    "        self.b = None\n",
    "\n",
    "    def decision_function(self, X):\n",
    "        return np.dot(X, self.w) + self.b  # w.x + b\n",
    "\n",
    "    def hingeloss(self, w, b, x, y):\n",
    "        # Regularizer term\n",
    "        reg = 0.5 * (w * w)\n",
    "\n",
    "        for i in range(x.shape[0]):\n",
    "            # Optimization term\n",
    "            opt_term = y[i] * ((np.dot(w, x[i])) + b)\n",
    "            loss = reg + self.C * max(0, 1 - opt_term)\n",
    "\n",
    "        return loss[0]\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        # initialize\n",
    "        n_samples = X.shape[0]\n",
    "        n_features = X.shape[1]\n",
    "        self.w = np.zeros(n_features)\n",
    "        self.b = 0\n",
    "        losses = []\n",
    "\n",
    "        # convert y to signed value (-1, +1)\n",
    "        Y = np.where(Y <= 0, -1, 1)\n",
    "\n",
    "        # gradient descent optimization start\n",
    "        for i in range(self.iterations):\n",
    "            l = self.hingeloss(self.w, self.b, X, Y)\n",
    "            losses.append(l)\n",
    "\n",
    "            # iterate through samples with batch_size as interval\n",
    "            for batch_start in range(0, n_samples, self.batch_size):\n",
    "                gradw = 0\n",
    "                gradb = 0\n",
    "                for x in range(batch_start, batch_start + self.batch_size):\n",
    "                    if x >= n_samples:\n",
    "                        break\n",
    "                     # correct classification\n",
    "                    if Y[x] * self.decision_function(X[x]) >= 1:\n",
    "                        gradw += 0  # w = w - *w\n",
    "                        gradb += 0  # b = b\n",
    "                    # misclassification\n",
    "                    else:\n",
    "                        # w = w - *(w - C*yi*xi)\n",
    "                        gradw += self.C * Y[x] * X[x]\n",
    "                        gradb += self.C * Y[x]  # b = b + *(C*yi)\n",
    "\n",
    "                # Updating weights and bias\n",
    "                self.w = self.w - self.learning_rate * self.w + self.learning_rate * gradw\n",
    "                self.b = self.b + self.learning_rate * gradb\n",
    "\n",
    "        return self.w, self.b, losses\n",
    "\n",
    "    def predict(self, X):\n",
    "        prediction = self.decision_function(X)\n",
    "        label_signs = np.sign(prediction)\n",
    "        result = np.where(label_signs <= -1, 0, 1)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM_Non_Linear_Scratch:\n",
    "    def __init__(self, kernel='poly', C=1, degree=2, const=1, sigma=0.1, iterations=1000, learning_rate= 0.001):\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        self.alpha = None\n",
    "        self.ones = None\n",
    "        self.b = 0\n",
    "        self.C = C\n",
    "        self.iterations = iterations\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        if kernel == 'poly':\n",
    "            self.kernel = self.polynomial_kernel\n",
    "            self.degree = degree\n",
    "            self.const = const\n",
    "        elif kernel == 'rbf':\n",
    "            self.kernel =  self.gaussian_kernel\n",
    "            self.sigma = sigma\n",
    "\n",
    "    def polynomial_kernel(self, X, Z):\n",
    "        # K(X, Z) = (c + X.Z)^degree\n",
    "        return (self.const + X.dot(Z.T))**self.degree\n",
    "\n",
    "    def gaussian_kernel(self, X, Z):\n",
    "        # K(X, Z) = e^( -(1/ 2) * ||X-Z||^2 )\n",
    "        return np.exp(-(1 / self.sigma ** 2) * np.linalg.norm(X[:, np.newaxis] - Z[np.newaxis, :], axis=2) ** 2)\n",
    "\n",
    "    def decision_function(self, X):\n",
    "        #  = sign( (i*yi).K(xi, xi) + b )\n",
    "        return (self.alpha * self.y).dot(self.kernel(self.X, X)) + self.b\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        y = np.where(y <= 0, -1, 1)\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.alpha = np.random.random(X.shape[0])\n",
    "        self.ones = np.ones(X.shape[0])\n",
    "        self.b = 0\n",
    "        losses = []\n",
    "\n",
    "        # (yi*yj) * K(xi, xj)\n",
    "        kernel_mat = np.outer(y, y) * self.kernel(X, X)\n",
    "\n",
    "        for i in range(self.iterations):\n",
    "            # 1  yk * ( j*yj * K(xj, xk) )\n",
    "            gradient = self.ones - kernel_mat.dot(self.alpha)\n",
    "            #  =  + *(1  yk * ( j*yj * K(xj, xk) )) update as per gradient descent rule\n",
    "            self.alpha = self.alpha + self.learning_rate * gradient\n",
    "            # 0 <  < C\n",
    "            self.alpha[self.alpha > self.C] = self.C\n",
    "            self.alpha[self.alpha < 0] = 0\n",
    "            # ( i  (1/2) * i( j( i*j * (yi*yj) * K(xi, xj) ) ) )\n",
    "            loss = np.sum(self.alpha) - 0.5 * np.sum(np.outer(self.alpha, self.alpha) * kernel_mat)\n",
    "            losses.append(loss)\n",
    "\n",
    "        # for bias, only consider  which 0 <  < C\n",
    "        # b = avg(0iC){ yi  ( j*yj * K(xj, xi) ) }\n",
    "        index = np.where((self.alpha) > 0 & (self.alpha < self.C))[0]\n",
    "        b_ind = y[index] - (self.alpha * y).dot(self.kernel(X, X[index]))\n",
    "        self.b = np.mean(b_ind)\n",
    "\n",
    "        return self.alpha, self.b, losses\n",
    "\n",
    "    def predict(self, X):\n",
    "        prediction = self.decision_function(X)\n",
    "        label_signs = np.sign(prediction)\n",
    "        result = np.where(label_signs <= -1, 0, 1)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scikit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_svm_model = LinearSVC(C=1, loss=\"hinge\")\n",
    "linear_svm_model.fit(X_train, y_train)\n",
    "y_pred_svm = linear_svm_model.predict(X_test)\n",
    "print(\"Support Vector Machine Report:\\n\",\n",
    "      classification_report(y_test, y_pred_svm))\n",
    "joblib.dump(linear_svm_model, 'models/linear_svm_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(linear_svm_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForestClassifierFromScratch:\n",
    "    def __init__(self, max_feature=None, n_trees=100, min_sample_split=2, min_impurity=1e-7, max_depth=10, criterion='gini'):\n",
    "        # Initialize the trees.\n",
    "        self.trees = []\n",
    "        for _ in range(n_trees):\n",
    "            self.trees.append(DecisionTreeClassifierFromScratch(min_sample_split=min_sample_split, min_impurity=min_impurity,\n",
    "                                                                max_depth=max_depth, criterion=criterion))\n",
    "\n",
    "        self.tree_feature_indexes = []\n",
    "        # Number of trees/estimetors.\n",
    "        self.n_estimators = n_trees\n",
    "        # How many features can be used for a tree from the whole features.\n",
    "        self.max_features = max_feature\n",
    "        # Aggication function to find the prediction.\n",
    "        self.prediction_aggrigation_calculation = self._maximum_vote_calculation\n",
    "\n",
    "    def _maximum_vote_calculation(self, y_preds):\n",
    "        # Find which prediction class has higest frequency in all tree prediction for each sample.\n",
    "        # create a empty array to store the prediction.\n",
    "        y_pred = np.empty((y_preds.shape[0], 1))\n",
    "        # iterate over all the data samples.\n",
    "        for i, sample_predictions in enumerate(y_preds):\n",
    "            y_pred[i] = np.bincount(sample_predictions.astype('int')).argmax()\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "    def _make_random_subset(self, X, y, n_subsets, replacement=True):\n",
    "        # Create a random subset of dataset with/without replacement.\n",
    "        subset = []\n",
    "        # use 100% of data when replacement is true , use 50% otherwise.\n",
    "        sample_size = (X.shape[0] if replacement else (X.shape[0] // 2))\n",
    "\n",
    "        # Add y as last column of X\n",
    "        Xy = np.column_stack((X, y))\n",
    "        np.random.shuffle(Xy)\n",
    "        # Select randome subset of data with replacement.\n",
    "        for i in range(n_subsets):\n",
    "            index = np.random.choice(range(sample_size), size=np.shape(\n",
    "                range(sample_size)), replace=replacement)\n",
    "            X = Xy[index][:, :-1]\n",
    "            y = Xy[index][:, -1]\n",
    "            subset.append({\"X\": X, \"y\": y})\n",
    "        return subset\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # if the max_features is not given then select it as square root of no on feature availabe.\n",
    "        n_features = X.shape[1]\n",
    "        if self.max_features == None:\n",
    "            self.max_features = int(round(np.sqrt(n_features)))\n",
    "\n",
    "        # Split the dataset into number of subsets equal to n_estimators.\n",
    "        subsets = self._make_random_subset(X, y, self.n_estimators)\n",
    "\n",
    "        for i, subset in enumerate(subsets):\n",
    "            X_subset, y_subset = subset[\"X\"], subset[\"y\"]\n",
    "            # select a random sucset of features for each tree. This is called feature bagging.\n",
    "            idx = np.random.choice(\n",
    "                range(n_features), size=self.max_features, replace=True)\n",
    "            # track this for prediction.\n",
    "            self.tree_feature_indexes.append(idx)\n",
    "            # Get the X with the selected features only.\n",
    "            X_subset = X_subset[:, idx]\n",
    "\n",
    "            # change the y_subet to i dimentional array.\n",
    "            y_subset = np.expand_dims(y_subset, axis=1)\n",
    "            # build the model with selected features and selected random subset from dataset.\n",
    "            self.trees[i].fit(X_subset, y_subset)\n",
    "\n",
    "    def predict(self, test_X):\n",
    "        y_preds = np.empty((test_X.shape[0], self.n_estimators))\n",
    "        # find the prediction from each tree for each samples\n",
    "        for i, tree in enumerate(self.trees):\n",
    "            features_index = self.tree_feature_indexes[i]\n",
    "            X_selected_features = test_X[:, features_index]\n",
    "            if isinstance(tree, DecisionTreeClassifier):\n",
    "                y_preds[:, i] = tree.predict(\n",
    "                    X_selected_features).reshape((-1,))\n",
    "            else:\n",
    "                y_preds[:, i] = tree.predict(X_selected_features)\n",
    "        # find the aggregated output.\n",
    "        y_pred = self.prediction_aggrigation_calculation(y_preds)\n",
    "\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scikit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Random Forest\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "print(\"Random Forest Report:\\n\", classification_report(y_test, y_pred_rf))\n",
    "joblib.dump(rf_model, 'models/random_forest_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(rf_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_variance_ratio(pca):\n",
    "    plt.plot(range(1, len(pca.explained_variance_ratio_) + 1),\n",
    "             np.cumsum(pca.explained_variance_ratio_),\n",
    "             linestyle='-', marker='o')\n",
    "    plt.grid(linestyle='-', linewidth=1)\n",
    "    plt.xlim([0, 22])\n",
    "    plt.ylim([0, 1])\n",
    "\n",
    "    yticks = np.arange(0, 1.1, 0.1)\n",
    "    plt.yticks(yticks)\n",
    "\n",
    "    xticks = np.arange(0, X.shape[1]+1, 1)\n",
    "    plt.xticks(xticks)\n",
    "\n",
    "    plt.xlabel('Number of components')\n",
    "    plt.ylabel('Cumulative explained variance')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Dimensionality Reduction using PCA for Random Forest\n",
    "pca = PCA(n_components=5)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "plot_variance_ratio(pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 6. Dimensionality Reduction using PCA for SVM\n",
    "linear_svm_model_pca = LinearSVC(C=1, loss=\"hinge\")\n",
    "linear_svm_model_pca.fit(X_train_pca, y_train)\n",
    "y_pred_svm_pca = linear_svm_model_pca.predict(X_test_pca)\n",
    "print(\"Support Vector Machine with PCA Report:\\n\",\n",
    "      classification_report(y_test, y_pred_svm_pca))\n",
    "joblib.dump(linear_svm_model_pca, 'models/linear_svm_pca_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(linear_svm_model_pca, X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model_pca = RandomForestClassifier()\n",
    "rf_model_pca.fit(X_train_pca, y_train)\n",
    "y_pred_rf_pca = rf_model_pca.predict(X_test_pca)\n",
    "print(\"Random Forest with PCA Report:\\n\",\n",
    "      classification_report(y_test, y_pred_rf_pca))\n",
    "joblib.dump(rf_model_pca, 'models/random_forest_pca_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(rf_model_pca, X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we will create a helper function to calculate the Euclidean distance between two points.\n",
    "def euclidean(point, centroid):\n",
    "  return np.sqrt(np.sum((point - centroid) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showplotwithclass(sorted_x, centroids):\n",
    "    plt.figure(figsize=(9, 3.5))\n",
    "\n",
    "    colors = plt.cm.tab20.colors\n",
    "\n",
    "    for i, cluster_points in enumerate(sorted_x):\n",
    "        if len(cluster_points) == 0:  # Skip empty clusters\n",
    "            continue\n",
    "        cluster_points = np.array(cluster_points)\n",
    "        plt.plot(cluster_points[:, 0], cluster_points[:, 1],\n",
    "                 marker='o', linestyle='', color=colors[i % len(colors)],\n",
    "                 label=f\"Class {i + 1} instances\")\n",
    "\n",
    "    plt.plot([x for x, _ in centroids],\n",
    "             [y for _, y in centroids],\n",
    "             'k+', markersize=10, label=\"Centroids\")\n",
    "\n",
    "    plt.xlabel(\"Petal length\", fontsize=10)\n",
    "    plt.ylabel(\"Petal width\", fontsize=10)\n",
    "    plt.legend(fontsize=10)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateClass(X, centroids, n_clusters):\n",
    "    sorted_x = [[] for _ in range(n_clusters)]  # Independent lists\n",
    "    for x in X:\n",
    "        dists = [euclidean(x, centroid) for centroid in centroids]\n",
    "        centroid_idx = np.argmin(dists)\n",
    "        sorted_x[centroid_idx].append(x)\n",
    "\n",
    "    sorted_x = [np.array(cluster) for cluster in sorted_x]\n",
    "\n",
    "    showplotwithclass(sorted_x, centroids)\n",
    "    return sorted_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjustCentroid(sorted_x, centroids):\n",
    "    prev_centroids = centroids\n",
    "    centroids = [np.mean(cluster, axis=0) for cluster in sorted_x]\n",
    "    for i, centroid in enumerate(centroids):\n",
    "        # Catch any np.nans, resulting from a centroid having no points\n",
    "        if np.isnan(centroid).any():\n",
    "            centroids[i] = prev_centroids[i]\n",
    "\n",
    "    showplotwithclass(sorted_x, centroids)\n",
    "    return centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import uniform\n",
    "\n",
    "def random_forest_train(X, n_clusters):\n",
    "    minpoint, maxpoint = np.min(X[:, :], axis=0), np.max(X[:, :], axis=0)\n",
    "    centroids = np.array([uniform(low=minpoint, high=maxpoint)\n",
    "                         for _ in range(n_clusters)])\n",
    "    while True:\n",
    "        sorted_x = calculateClass(X, centroids, n_clusters)\n",
    "        new_centroid = adjustCentroid(sorted_x, centroids)\n",
    "        if np.allclose(centroids, new_centroid):\n",
    "            break\n",
    "        centroids = new_centroid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scikit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. K-Means Clustering (Unsupervised)\n",
    "kmeans = KMeans(n_clusters=2)\n",
    "df['kmeans_cluster'] = kmeans.fit_predict(X)\n",
    "\n",
    "# Plot K-Means clustering results\n",
    "plt.figure(figsize=(10, 6))\n",
    "for feature in X.columns:\n",
    "    sns.scatterplot(x=df[feature], y=df['House overall [kW]'],\n",
    "                hue=df['kmeans_cluster'], palette='deep')\n",
    "    plt.title('K-Means Clustering Results')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgglomerativeClusteringScratch:\n",
    "    def __init__(self, n_clusters=None, linkage='average'):\n",
    "        # Use euclidean matric for computing pairwise distance matrix\n",
    "        self.n_clusters = n_clusters\n",
    "\n",
    "        if linkage == 'complete':\n",
    "            self.linkage_distance_func = self.max_linkage_distance\n",
    "        elif linkage == 'single':\n",
    "            self.linkage_distance_func = self.min_linkage_distance\n",
    "        else:\n",
    "            self.linkage_distance_func = self.avg_linkage_distance\n",
    "\n",
    "    def avg_linkage_distance(self, cluster_A, cluster_B):\n",
    "        # Compute average linkage distance between two clusters\n",
    "        distance = 0\n",
    "        for i in range(cluster_A.shape[0]):\n",
    "            distance += np.linalg.norm(cluster_B -\n",
    "                                       cluster_A[i, :], axis=1).sum()\n",
    "        distance /= (cluster_A.shape[0] * cluster_B.shape[0])\n",
    "        return distance\n",
    "\n",
    "    def max_linkage_distance(self, cluster_A, cluster_B):\n",
    "        # Compute maximum linkage distance between two clusters\n",
    "        distance = 0\n",
    "        for i in range(cluster_A.shape[0]):\n",
    "            distance = np.append(np.linalg.norm(\n",
    "                cluster_B - cluster_A[i, :], axis=1), distance).max()\n",
    "        return distance\n",
    "\n",
    "    def min_linkage_distance(self, cluster_A, cluster_B):\n",
    "        # Compute minimum linkage distance between two clusters\n",
    "        distance = np.inf\n",
    "        for i in range(cluster_A.shape[0]):\n",
    "            distance = np.append(np.linalg.norm(\n",
    "                cluster_B - cluster_A[i, :], axis=1), distance).min()\n",
    "        return distance\n",
    "\n",
    "    def pairwise_distance(self, data, n_samples):\n",
    "        # Compute the pairwise distance matrix in euclidean matric\n",
    "        distance_mat = np.zeros((n_samples, n_samples))\n",
    "        for i in range(n_samples):\n",
    "            for j in range(i + 1, n_samples):\n",
    "                distance = np.linalg.norm(data[i] - data[j])\n",
    "                distance_mat[i, j] = distance\n",
    "                distance_mat[j, i] = distance\n",
    "        return distance_mat\n",
    "\n",
    "    def update(self, data, distance_mat, labels):\n",
    "        # \"Find closest clusters, merge clusters, delete cluster, update distance\"\n",
    "        # Index of upper part of distance matrix (skip diagonal)\n",
    "        idx_upper = np.triu_indices(distance_mat.shape[0], k=1)\n",
    "        min_value = np.min(distance_mat[idx_upper])  # Value of idx_upper\n",
    "        row, col = np.argwhere(distance_mat == min_value)[\n",
    "            0]  # Index of min_value (same as d_kl)\n",
    "\n",
    "        # Update label\n",
    "        labels[labels == col] = row\n",
    "        labels[labels > col] -= 1\n",
    "\n",
    "        # Deleted the row and column 'col'\n",
    "        distance_mat = np.delete(distance_mat, col, 0)\n",
    "        distance_mat = np.delete(distance_mat, col, 1)\n",
    "\n",
    "        # Update distance matrix\n",
    "        for i in range(len(distance_mat)):\n",
    "            distance_mat[row, i] = self.linkage_distance_func(\n",
    "                data[labels == row], data[labels == i])\n",
    "            distance_mat[i, row] = distance_mat[row, i]\n",
    "        return distance_mat, labels\n",
    "\n",
    "    def fit_predict(self, X):\n",
    "        self.data = X\n",
    "        self.n_samples = self.data.shape[0]\n",
    "        self.initial_distance = self.pairwise_distance(\n",
    "            self.data, self.n_samples)\n",
    "        self.labels = np.arange(self.n_samples)\n",
    "        self.distance_matrix = self.initial_distance.copy()\n",
    "        while len(np.unique(self.labels)) > self.n_clusters:\n",
    "            # Fill in the diagonal as infinity to determine that the distance is the same position.\n",
    "            np.fill_diagonal(self.distance_matrix, np.inf)\n",
    "            self.distance_matrix, self.labels = self.update(\n",
    "                self.data, self.distance_matrix, self.labels)\n",
    "\n",
    "        return self.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scikit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Agglomerative Clustering (Unsupervised)\n",
    "df_sampled = df.sample(n=30000, random_state=42)\n",
    "X_sampled = df_sampled[X.columns]\n",
    "\n",
    "agglo = AgglomerativeClustering(n_clusters=2)\n",
    "df_sampled['agglo_cluster'] = agglo.fit_predict(X_sampled)\n",
    "\n",
    "# Plot Agglomerative Clustering results\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=df_sampled['temperature'], y=df_sampled['House overall [kW]'],\n",
    "                hue=df_sampled['agglo_cluster'], palette='deep')\n",
    "plt.title('Agglomerative Clustering Results')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    def __init__(self, input_dim, output_dim, activation=None):\n",
    "        # Generate weight with shape INPUT x OUTPUT (in this case 11 x 5 for the first part and 5 x 2 for the second part)\n",
    "        self.W = np.random.randn(input_dim, output_dim)\n",
    "        # Generate bias in the same shape as the output\n",
    "        self.b = np.random.randn(1, output_dim)\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.X = X\n",
    "        # Input(1 x X)  Weight (X x Y) => Output (1 x Y)\n",
    "        self.Z = np.dot(X, self.W)\n",
    "        self.Z += self.b  # Add bias to the output\n",
    "        # Pass the output to the activation function if we have it\n",
    "        if self.activation:\n",
    "            self.A = self.activation.forward(self.Z)\n",
    "        else:\n",
    "            self.A = self.Z\n",
    "        return self.A\n",
    "\n",
    "    def backward(self, dA):\n",
    "        # Calculate gradient according to loss received by backward propagation\n",
    "        if self.activation:\n",
    "            dZ = self.activation.backward(self.Z, dA)\n",
    "        else:\n",
    "            dZ = dA\n",
    "        dW = np.dot(self.X.T, dZ)\n",
    "        db = np.sum(dZ, axis=0, keepdims=True)\n",
    "        dX = np.dot(dZ, self.W.T)\n",
    "        return dW, db, dX\n",
    "\n",
    "\n",
    "class NeuralModel:\n",
    "    def __init__(self, layers_dim, activations):\n",
    "        self.layers = []\n",
    "        input_dim = layers_dim[0]\n",
    "        for output_dim, activation in zip(layers_dim[:-1], activations[:-1]):\n",
    "            self.layers.append(\n",
    "                Neuron(input_dim, output_dim, activation=activation))\n",
    "            input_dim = output_dim\n",
    "        # Last layer activation\n",
    "        self.layers.append(\n",
    "            Neuron(input_dim, layers_dim[-1], activation=activations[-1]))\n",
    "        self.loss = []\n",
    "\n",
    "    def calculate_loss(self, X, y):\n",
    "        # Calculate loss from true result compare the the predicted value\n",
    "        mse_loss = np.mean((self.predict(X) - y) ** 2)\n",
    "        return mse_loss\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Pass the input into hidden layers and propagate forward in neural network\n",
    "        input = X\n",
    "        for layer in self.layers:\n",
    "            input = layer.forward(input)\n",
    "        # the result here is passed through all the hidden layers\n",
    "        return input\n",
    "\n",
    "    def train(self, X, y, num_passes=20000, learning_rate=0.01, print_loss=False):\n",
    "        for epoch in range(num_passes):\n",
    "            # Forward propagation\n",
    "            input = X\n",
    "            for layer in self.layers:\n",
    "                input = layer.forward(input)\n",
    "\n",
    "            # Calculate the loss (Mean Squared Error)\n",
    "            loss = np.mean((input - y) ** 2)\n",
    "            self.loss.append(loss)\n",
    "\n",
    "            # Back propagation\n",
    "            dA = 2 * (input - y) / y.size\n",
    "            for layer in reversed(self.layers):\n",
    "                dW, db, dA = layer.backward(dA)\n",
    "                layer.W -= learning_rate * dW\n",
    "                layer.b -= learning_rate * db\n",
    "\n",
    "            if print_loss and epoch % 1000 == 0:\n",
    "                print(f\"Loss after iteration {epoch}: {loss:.6f}\")\n",
    "\n",
    "# Activation functions\n",
    "class ReLU:\n",
    "    @staticmethod\n",
    "    def forward(Z):\n",
    "        return np.maximum(0, Z)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(Z, dA):\n",
    "        return dA * (Z > 0)\n",
    "\n",
    "\n",
    "class Sigmoid:\n",
    "    @staticmethod\n",
    "    def forward(Z):\n",
    "        return 1 / (1 + np.exp(-Z))\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(Z, dA):\n",
    "        A = Sigmoid.forward(Z)\n",
    "        return dA * A * (1 - A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train)\n",
    "y_train_tensor = torch.FloatTensor(y_train.values).view(-1, 1)\n",
    "X_test_tensor = torch.FloatTensor(X_test)\n",
    "y_test_tensor = torch.FloatTensor(y_test.values).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Single-Layer Perceptron (SLP) Model\n",
    "class SLP(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(SLP, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return self.sigmoid(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Multi-Layer Perceptron (MLP) Model\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.hidden1 = nn.Linear(input_size, 32)\n",
    "        self.hidden2 = nn.Linear(32, 32)\n",
    "        self.output = nn.Linear(32, 1)          \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.hidden1(x))\n",
    "        x = torch.relu(self.hidden2(x))\n",
    "        x = self.output(x)                          \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate models\n",
    "input_size = X_train.shape[1]\n",
    "slp_model = SLP(input_size)\n",
    "mlp_model = MLP(input_size)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()  # Binary Cross-Entropy Loss\n",
    "slp_optimizer = optim.Adam(slp_model.parameters(), lr=0.001)\n",
    "mlp_optimizer = optim.Adam(mlp_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Function\n",
    "def train_model(model, optimizer, X_train, y_train, epochs=100):\n",
    "    model.train()  # Set the model to training mode\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train)\n",
    "        loss = criterion(outputs, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "    return model\n",
    "\n",
    "\n",
    "# Train SLP Model\n",
    "print(\"Training Single-Layer Perceptron (SLP):\")\n",
    "model_output_slp = train_model(slp_model, slp_optimizer, X_train_tensor, y_train_tensor)\n",
    "\n",
    "# Train MLP Model\n",
    "print(\"Training Multi-Layer Perceptron (MLP):\")\n",
    "model_output_mlp = train_model(mlp_model, mlp_optimizer, X_train_tensor, y_train_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_nn_model(model, X_test):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_test)\n",
    "        y_pred_classes = (y_pred >= 0.5).float()\n",
    "    return y_pred_classes\n",
    "\n",
    "def plot_nn_model_loss(model):\n",
    "    y_test = y_test_tensor.numpy()\n",
    "    predictions = evaluate_nn_model(model, X_test_tensor).numpy()\n",
    "\n",
    "    # Create a DataFrame for easy plotting\n",
    "    results_df = pd.DataFrame({\n",
    "        'True Labels': y_test.flatten(),\n",
    "        'Predicted Labels': predictions.flatten()\n",
    "    })\n",
    "\n",
    "    downsample_factor = 500\n",
    "    results_df_downsampled = results_df.iloc[::downsample_factor, :].reset_index(drop=True)\n",
    "    \n",
    "    # Create a step plot\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    plt.step(results_df_downsampled.index, results_df_downsampled['True Labels'], label='True Labels', where='post', color='blue', alpha=0.7)\n",
    "    plt.step(results_df_downsampled.index, results_df_downsampled['Predicted Labels'], label='Predicted Labels', where='post', color='red', alpha=0.7)\n",
    "    plt.title('True vs Predicted Labels Over Time (Step Plot)')\n",
    "    plt.xlabel('Sample Index (Downsampled)')\n",
    "    plt.ylabel('Labels')\n",
    "    plt.yticks([0, 1], ['Normal', 'Anomaly'])  # Update y-axis labels for clarity\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_nn_model_loss(model_output_slp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_nn_model_loss(model_output_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate SLP Model\n",
    "y_pred_slp = evaluate_nn_model(slp_model, X_test_tensor)\n",
    "print(\"SLP Classification Report:\\n\",\n",
    "      classification_report(y_test, y_pred_slp.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate MLP Model\n",
    "y_pred_mlp = evaluate_nn_model(mlp_model, X_test_tensor)\n",
    "print(\"MLP Classification Report:\\n\",\n",
    "      classification_report(y_test, y_pred_mlp.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After training the models, save them\n",
    "torch.save(slp_model.state_dict(), 'models/slp_model.pth')\n",
    "print(\"Single-Layer Perceptron model saved as 'models/slp_model.pth'\")\n",
    "\n",
    "torch.save(mlp_model.state_dict(), 'models/mlp_model.pth')\n",
    "print(\"Multi-Layer Perceptron model saved as 'models/mlp_model.pth'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Intro-Data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
